# Serial and Parallel Processing - From Python to Pyspark

In this repository you will find a simple example of code translation from Python to Pyspark, along with serial and parallel processing implementations - the latter using RDD (you may find more information on RDD at https://spark.apache.org/docs/latest/rdd-programming-guide.html).

The dataset used for these examples contained the yellow and green 2017 taxi trip records (January & February), including fields capturing pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts. The data was collected and provided to the NYC Taxi and Limousine Commission (TLC) by technology providers authorized under the Taxicab & Livery Passenger Enhancement Programs (TPEP/LPEP). The trip data was not created by the TLC, and TLC makes no representations as to the accuracy of these data. You can find more information of the dataset in the following link: 
https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page

If you have issues fetching the datasets, feel free to contact me. I'll be happy share them with you as I wasn't able to upload them here on GitHun given the size restrictions - 50+MB
